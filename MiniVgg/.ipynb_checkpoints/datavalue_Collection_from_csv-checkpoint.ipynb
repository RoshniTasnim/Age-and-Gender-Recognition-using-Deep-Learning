{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "##Test from customize image\n",
    "## importing classes from the file that is located in the different folder\n",
    "import import_ipynb\n",
    "from tensorflow.keras import backend as k\n",
    "from pyimagesearch.minivggnet import MiniVGGNet\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import load_model\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "import imutils \n",
    "from imutils import paths\n",
    "from keras.optimizers import Adam\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading imagepaths csv files and arranging datas according to the imagepath from folders\n",
    "datapaths = ['../Dataset/AdienceDataset/original/csv/fold_0_data.csv','../Dataset/AdienceDataset/csv/fold_1_data.csv','../Dataset/AdienceDataset/csv/fold_2_data.csv','../Dataset/AdienceDataset/csv/fold_3_data.csv','../Dataset/AdienceDataset/csv/fold_4_data.csv']\n",
    "image_size=(75,75)\n",
    "folder= []\n",
    "filename = []\n",
    "faceid = []\n",
    "age = []\n",
    "gender = []\n",
    "for datapath in datapaths:\n",
    "    #print (datapath)\n",
    "    data = pd.read_csv(datapath)\n",
    "    folder +=  data['user_id'].tolist()\n",
    "    filename += data['original_image'].tolist()\n",
    "    faceid += data['face_id'].tolist()\n",
    "    age += data['age'].tolist()\n",
    "    gender += data['gender'].tolist()  \n",
    "folder = np.array(folder)\n",
    "filename = np.array(filename)\n",
    "faceid  = np.array(faceid).astype(int)\n",
    "age = np.array(age)\n",
    "gender = np.array(gender)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n"
     ]
    }
   ],
   "source": [
    "# grab the image paths and randomly shuffle them\n",
    "print(\"[INFO] loading images...\")\n",
    "imPath = []\n",
    "inPath = \"../Dataset/AdienceDataset/aligned/\"\n",
    "fileex=\"landmark_aligned_face\"\n",
    "for i in range (folder.shape[0]):   \n",
    "    path = inPath+str(folder[i])+\"/\"+fileex+\".\"+str(faceid[i])+\".\"+str(filename[i])\n",
    "    imPath.append(path)\n",
    "imPath = np.array(imPath, dtype= str)    \n",
    "#random.seed(42)\n",
    "#random.shuffle(imPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the data and label creation\n",
    "datavalue = []\n",
    "# loop over the input images\n",
    "for i in range(imPath.shape[0]):\n",
    "    # load the image, pre-process it, and store it in the data list\n",
    "    image = cv2.imread(imPath[i], 1)\n",
    "    image = cv2.resize(image,image_size)\n",
    "    image1 = img_to_array(image)\n",
    "    datavalue.append(image1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the raw pixel intensities to the range [0, 1]\n",
    "datavalue = np.array(datavalue, dtype=\"float\") / 255.0\n",
    "datavalue = datavalue - 0.5\n",
    "datavalue = datavalue* 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the data and label as pickel\n",
    "import pickle\n",
    "\n",
    "f = open(\"../pickle/X_ocsv4_75.pickle\", \"wb\")\n",
    "f.write(pickle.dumps(datavalue))\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
