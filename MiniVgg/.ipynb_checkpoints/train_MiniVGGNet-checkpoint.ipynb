{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "##Test from customize image\n",
    "## importing classes from the file that is located in the different folder\n",
    "import import_ipynb\n",
    "from tensorflow.keras import backend as k\n",
    "from pyimagesearch.minivggnet import MiniVGGNet\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import load_model\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "import imutils \n",
    "from imutils import paths\n",
    "from keras.optimizers import Adam\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "DATA_PATH = \"../pickle\"\n",
    "infile = open(DATA_PATH+'/X_48.pickle','rb')\n",
    "datavalue = pickle.load(infile)\n",
    "\n",
    "labelfile = open(DATA_PATH+'/Y_48_withoutmlb.pickle','rb')\n",
    "labels = pickle.load(labelfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] class labels:\n",
      "1. (0, 2)\n",
      "2. (15, 20)\n",
      "3. (25, 32)\n",
      "4. (38, 43)\n",
      "5. (4, 6)\n",
      "6. (48, 53)\n",
      "7. (60, 100)\n",
      "8. (8, 12)\n",
      "9. f\n",
      "10. m\n"
     ]
    }
   ],
   "source": [
    "labels = np.array(labels)\n",
    "\n",
    "# binarize the labels using scikit-learn's special multi-label\n",
    "# binarizer implementation\n",
    "print(\"[INFO] class labels:\")\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels = mlb.fit_transform(labels)\n",
    "\n",
    "# loop over each of the possible class labels and show them\n",
    "for (i, label) in enumerate(mlb.classes_):\n",
    "\tprint(\"{}. {}\".format(i + 1, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition the data into training and testing splits using 80% of\n",
    "# the data for training and the remaining 20% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(datavalue,\n",
    "\tlabels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the data and label as pickel\n",
    "import pickle\n",
    "\n",
    "f = open(\"trainX_48.pickle\", \"wb\")\n",
    "f.write(pickle.dumps(trainX))\n",
    "f.close()\n",
    "\n",
    "f = open(\"trainY_48.pickle\", \"wb\")\n",
    "f.write(pickle.dumps(trainY))\n",
    "f.close()\n",
    "\n",
    "f = open(\"testX_48.pickle\", \"wb\")\n",
    "f.write(pickle.dumps(testX))\n",
    "f.close()\n",
    "\n",
    "f = open(\"testY_48.pickle\", \"wb\")\n",
    "f.write(pickle.dumps(testY))\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    }
   ],
   "source": [
    "# initialize the number of epochs to train for, initial learning rate,\n",
    "# batch size, and image dimensions\n",
    "NUM_EPOCHS = 5\n",
    "INIT_LR = 1e-2\n",
    "BS = 32\n",
    "IMAGE_DIMS = (48, 48, 3)\n",
    "\n",
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n",
    "\theight_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "\thorizontal_flip=True, fill_mode=\"nearest\")\n",
    "\n",
    "# initialize the optimizer and model\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = SGD(lr=INIT_LR, momentum=0.9, decay=INIT_LR / NUM_EPOCHS)\n",
    "model = MiniVGGNet.build(width=IMAGE_DIMS[1], height=IMAGE_DIMS[0], depth=IMAGE_DIMS[2], classes=len(mlb.classes_))\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n",
      "Epoch 1/5\n",
      "383/383 [==============================] - 694s 2s/step - loss: 0.6107 - acc: 0.7119 - val_loss: 0.4045 - val_acc: 0.8339\n",
      "Epoch 2/5\n",
      "383/383 [==============================] - 648s 2s/step - loss: 0.4451 - acc: 0.8129 - val_loss: 0.3817 - val_acc: 0.8419\n",
      "Epoch 3/5\n",
      "383/383 [==============================] - 658s 2s/step - loss: 0.4225 - acc: 0.8252 - val_loss: 0.3703 - val_acc: 0.8462\n",
      "Epoch 4/5\n",
      "383/383 [==============================] - 633s 2s/step - loss: 0.4123 - acc: 0.8289 - val_loss: 0.3693 - val_acc: 0.8459\n",
      "Epoch 5/5\n",
      "383/383 [==============================] - 640s 2s/step - loss: 0.4037 - acc: 0.8317 - val_loss: 0.3639 - val_acc: 0.8477\n"
     ]
    }
   ],
   "source": [
    "# train the network\n",
    "print(\"[INFO] training network...\")\n",
    "H = model.fit_generator(\n",
    "\taug.flow(trainX, trainY, batch_size=BS),\n",
    "\tvalidation_data=(testX, testY),\n",
    "\tsteps_per_epoch=len(trainX) // BS,\n",
    "\tepochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "print(\"[INFO] serializing network...\")\n",
    "model.save(\"AgeGender_MiniVGG_V1.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameter size\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the Training and Validation Loss\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "N = NUM_EPOCHS\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.savefig(\"MiniVGG_V2_Training_Validation_Loss_plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training and Validation accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "N = NUM_EPOCHS\n",
    "plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training and Validation Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.savefig(\"MiniVGG_V2_Training_Validation_Accuracy_plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshni\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Roshni\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      (0, 2)       0.83      0.04      0.08       250\n",
      "    (15, 20)       0.00      0.00      0.00       357\n",
      "    (25, 32)       0.44      0.00      0.01       824\n",
      "    (38, 43)       0.00      0.00      0.00       501\n",
      "      (4, 6)       0.60      0.01      0.01       396\n",
      "    (48, 53)       0.00      0.00      0.00       174\n",
      "   (60, 100)       0.00      0.00      0.00       155\n",
      "     (8, 12)       0.00      0.00      0.00       411\n",
      "           f       0.00      0.00      0.00         0\n",
      "           m       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.01      3068\n",
      "   macro avg       0.19      0.01      0.01      3068\n",
      "weighted avg       0.26      0.01      0.01      3068\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labelNames = mlb.classes_\n",
    "# make predictions on the test set\n",
    "preds = model.predict(testX)\n",
    "\n",
    "# show a nicely formatted classification report\n",
    "print(\"[INFO] evaluating network...\")\n",
    "print(classification_report(testY.argmax(axis=1), preds.argmax(axis=1),\n",
    "\ttarget_names=labelNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:: 0.005541069100391135\n",
      "precision Score:: 0.18777777777777777\n",
      "recall Score:: 0.005243012650779641\n",
      "f1 Score:: 0.010090231291541952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshni\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Roshni\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Roshni\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Roshni\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#show Classification_report\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "testY_F = testY.argmax( axis=1)\n",
    "prediction_F = preds.argmax( axis=1)\n",
    "\n",
    "#print(confusion_matrix(testY_F, prediction_F))\n",
    "print('Accuracy Score::', accuracy_score(testY_F, prediction_F))\n",
    "\n",
    "print('precision Score::', precision_score(testY_F, prediction_F, average = 'macro'))\n",
    "print('recall Score::', recall_score(testY_F, prediction_F, average = 'macro'))\n",
    "print('f1 Score::', f1_score(testY_F, prediction_F, average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(testY_F, prediction_F, classes=labelNames,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(testY_F, prediction_F, classes=labelNames, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the image that classified wrongly\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "notClassified = []\n",
    "for i in range(testY_F.shape[0]):\n",
    "  if (testY_F[i] == prediction_F[i]):\n",
    "    continue\n",
    "  else:\n",
    "    notClassified.append(i)\n",
    "    \n",
    "notClassified = np.array(notClassified)\n",
    "print('Enter the value in range:', notClassified.size)\n",
    "index_val = input(\"Enter the value:\")\n",
    "index_val = int (index_val)\n",
    "index = notClassified[index_val]\n",
    "\n",
    "print('The actual label:', labelNames[testY_F[index]])\n",
    "print('The predicted label:', labelNames[prediction_F[index]])\n",
    "\n",
    "im = cv2.resize(testX[index], (100, 100))\n",
    "plt.imshow(im)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize our list of output images\n",
    "images = []\n",
    "\n",
    "# randomly select a few testing fashion items\n",
    "for i in np.random.choice(np.arange(0, len(testY)), size=(16,)):\n",
    "\t# classify the clothing\n",
    "\tprobs = model.predict(testX[np.newaxis, i])\n",
    "\tprediction = probs.argmax(axis=1)\n",
    "\tlabel = labelNames[prediction[0]]\n",
    " \n",
    "\t# extract the image from the testData if using \"channels_first\"\n",
    "\t# ordering\n",
    "\tif K.image_data_format() == \"channels_first\":\n",
    "\t\timage = (testX[i][0] * 255).astype(\"uint8\")\n",
    " \n",
    "\t# otherwise we are using \"channels_last\" ordering\n",
    "\telse:\n",
    "\t\timage = (testX[i] * 255).astype(\"uint8\")\n",
    "\n",
    "\t# initialize the text label color as green (correct)\n",
    "\tcolor = (0, 255, 0)\n",
    "\n",
    "\t# otherwise, the class label prediction is incorrect\n",
    "\tif prediction[0] != np.argmax(testY[i]):\n",
    "\t\tcolor = (0, 0, 255)\n",
    " \n",
    "\t# merge the channels into one image and resize the image from\n",
    "\t# 28x28 to 96x96 so we can better see it and then draw the\n",
    "\t# predicted label on the image\n",
    "\timage = cv2.merge([image] * 3)\n",
    "\timage = cv2.resize(image, (96, 96), interpolation=cv2.INTER_LINEAR)\n",
    "\tcv2.putText(image, label, (5, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.75,\n",
    "\t\tcolor, 2)\n",
    "\n",
    "\t# add the image to our list of output images\n",
    "\timages.append(image)\n",
    "\n",
    "# construct the montage for the images\n",
    "montage = build_montages(images, (96, 96), (4, 4))[0]\n",
    "\n",
    "# show the output montage\n",
    "plt.imshow(\"Fashion MNIST\", montage)\n",
    "plt.show()\n",
    "#cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
