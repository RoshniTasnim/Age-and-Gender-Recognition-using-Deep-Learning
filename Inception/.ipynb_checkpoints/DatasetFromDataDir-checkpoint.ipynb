{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from C:\\Users\\abssa\\Thesis\\Proposed_Model\\imagesearch\\hactivitynet.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# set the matplotlib backend so figures can be saved in the backgrou\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import import_ipynb\n",
    "# import the necessary packages\n",
    "# pip install --upgrade import-ipynb\n",
    "from imagesearch.hactivitynet import HactivityNet\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.optimizers import SGD\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras import backend as K\n",
    "from imutils import build_montages\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "\n",
    "def create_training_data(CATEGORIES, DATADIR, IMG_SIZE):\n",
    "    for category in CATEGORIES:  # do dogs and cats\n",
    "\n",
    "        path = os.path.join(DATADIR,category)  # create path to dogs and cats\n",
    "        #print('Path:', path)\n",
    "        class_num = CATEGORIES.index(category)  # get the classification  (0 or a 1). 0=dog 1=cat\n",
    "        #print('class', class_num)\n",
    "        for img in tqdm(os.listdir(path)):  # iterate over each image per dogs and cats\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n",
    "                #print('Image:', new_array)\n",
    "                training_data.append([new_array, class_num])  # add this to our training_data\n",
    "            except Exception as e:  # in the interest in keeping the output clean...\n",
    "                pass\n",
    "    training_data1= np.array(training_data)\n",
    "    print('Training data shape:', training_data1.shape)       \n",
    "    random.shuffle(training_data)\n",
    "    \n",
    "    X = []\n",
    "    Y = []\n",
    "    for data, label in training_data:\n",
    "        X.append(data)\n",
    "        Y.append(label)\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    print(X.shape)\n",
    "    print(Y.shape)\n",
    "    return (X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 8128/8128 [01:04<00:00, 125.56it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 8399/8399 [00:45<00:00, 184.56it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 8273/8273 [01:02<00:00, 132.45it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 8292/8292 [00:52<00:00, 158.36it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 8015/8015 [00:57<00:00, 140.42it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 8196/8196 [00:26<00:00, 307.34it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 8138/8138 [00:52<00:00, 153.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (57441, 2)\n",
      "(57441, 48, 48)\n",
      "(57441,)\n"
     ]
    }
   ],
   "source": [
    "# this the dataset will be automatically downloaded)\n",
    "DATADIR = \"E:/Thesis/Dataset/Image_dataset\"\n",
    "\n",
    "CATEGORIES = [\"Boxing\", \"HandClapping\", \"HandWaving\", \"Jogging\", \"Running\", \"Standing\", \"Walking\"]\n",
    "#CATEGORIES = [\"Standing1\"]\n",
    "IMG_SIZE = 48\n",
    "XX, YY = create_training_data(CATEGORIES, DATADIR, IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57441,)\n"
     ]
    }
   ],
   "source": [
    "print(YY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "(trainX,testX, trainY, testY) = train_test_split(XX, YY, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "f = open(\"trainX.pickle\", \"wb\")\n",
    "f.write(pickle.dumps(trainX))\n",
    "f.close()\n",
    "\n",
    "f = open(\"trainY.pickle\", \"wb\")\n",
    "f.write(pickle.dumps(trainY))\n",
    "f.close()\n",
    "\n",
    "f = open(\"testX.pickle\", \"wb\")\n",
    "f.write(pickle.dumps(testX))\n",
    "f.close()\n",
    "\n",
    "f = open(\"testY.pickle\", \"wb\")\n",
    "f.write(pickle.dumps(testY))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
