{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "##Test from customize image\n",
    "## importing classes from the file that is located in the different folder\n",
    "import import_ipynb\n",
    "from tensorflow.keras import backend as k\n",
    "#from pyimagesearch.minivggnet import MiniVGGNet\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import load_model\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "import imutils \n",
    "from imutils import paths\n",
    "from keras.optimizers import Adam\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n"
     ]
    }
   ],
   "source": [
    "# grab the image paths and randomly shuffle them\n",
    "print(\"[INFO] loading images...\")\n",
    "imagePaths = sorted(list(paths.list_images(\"Preprocessed_dataset\")))\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the data and labels\n",
    "datavalue = []\n",
    "labels = []\n",
    "image_size=(75,75)\n",
    "\n",
    "# loop over the input images\n",
    "for imagePath in imagePaths:\n",
    "\t# load the image, pre-process it, and store it in the data list\n",
    "\timage = cv2.imread(imagePath)  \n",
    "\timage = cv2.resize(image, image_size)\n",
    "\timage = img_to_array(image)\n",
    "\tdatavalue.append(image)\n",
    "\n",
    "\t# extract set of class labels from the image path and update the\n",
    "\t# labels list\n",
    "\tl1 = label1 = imagePath.split(os.path.sep)[-3].split(\"_\")  \n",
    "\tl2 = label2 = imagePath.split(os.path.sep)[-2].split(\"_\")    \n",
    "\tl=l1+l2  \n",
    "\tlabels.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the data and label as pickel\n",
    "import pickle\n",
    "f = open(\"pickle/image_pickle/X_75.pickle\", \"wb\")\n",
    "f.write(pickle.dumps(datavalue))\n",
    "f.close()\n",
    "\n",
    "f = open(\"pickle/image_pickle/Y_75_withoutmlb.pickle\", \"wb\")\n",
    "f.write(pickle.dumps(labels))\n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'nbytes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-b6362f866c1f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m print(\"[INFO] data matrix: {} images ({:.2f}MB)\".format(\n\u001b[1;32m----> 3\u001b[1;33m \tlen(imagePaths), datavalue.nbytes / (1024 * 1000.0)))\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# binarize the labels using scikit-learn's special multi-label\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'nbytes'"
     ]
    }
   ],
   "source": [
    "labels = np.array(labels)\n",
    "print(\"[INFO] data matrix: {} images ({:.2f}MB)\".format(\n",
    "\tlen(imagePaths), datavalue.nbytes / (1024 * 1000.0)))\n",
    "\n",
    "# binarize the labels using scikit-learn's special multi-label\n",
    "# binarizer implementation\n",
    "print(\"[INFO] class labels:\")\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels = mlb.fit_transform(labels)\n",
    "\n",
    "# loop over each of the possible class labels and show them\n",
    "for (i, label) in enumerate(mlb.classes_):\n",
    "\tprint(\"{}. {}\".format(i + 1, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the data and label as pickel\n",
    "import pickle\n",
    "\n",
    "f = open(\"pickle/image_pickle/Y_75.pickle\", \"wb\")\n",
    "f.write(pickle.dumps(labels))\n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
